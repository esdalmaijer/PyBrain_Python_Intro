{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy\n",
    "\n",
    "In this worksheet, you'll learn more about data handling. This will include useful variable types, and also how to read data from files. A package that is great for this, is **NumPy**. This is not part of basic Python, but an external package that you can download and use with Python. (Note that it has already been included if you're viewing this notebook on MyBinder or Google Colab, and that it also comes with the Anaconda distribution.)\n",
    "\n",
    "As with any other module, you have to import numpy before you can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some people prefer importing numpy, but shortening the name by which they call it to `np`. This can be more confusing while reading code, but also saves you time while typing. To abbreviate a module when importing, you can use the `as` keyword, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy arrays\n",
    "\n",
    "NumPy's main feature, is its array. This is a variable type that is a bit like a list, but allows you to more easily manipulate its parts. Let's say you want to add `5` to a the list `[1,2,3,4]`. In traditional Python, you could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of values.\n",
    "my_numbers = [1,2,3,4]\n",
    "# Loop through all the values.\n",
    "for i in range(0, len(my_numbers)):\n",
    "    # Add five to the current value.\n",
    "    my_numbers[i] = my_numbers[i] + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent operation is much clearer in NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_numbers = numpy.array([1,2,3,4])\n",
    "my_numbers = my_numbers + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process of not applying an operation to each single value, but to the whole collection of values is called *vectorisation*. (NumPy arrays are sometimes referred to as vectors.) It's not only quicker to write, it's also quicker to run. This won't matter much for small examples like this, but quickly adds up to meaningful differences when you're working with real data.\n",
    "\n",
    "NumPy arrays do not have to be only a list, but can be multidimensional. Let's use NumPy's random module to generate some numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.random.rand(5,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find out the shape of a NumPy array by using its `shape` property. This is not a function/method, so you use `a.shape` instead of `a.shape()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array data types\n",
    "\n",
    "NumPy arrays have a data type, or `dtype` for short. This can be set by you when you generate them, or inferred by NumPy if you don't specify it yourself. This means that all values in the array are expected to have the same data type, which is different from Python's lists, which could contain anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4])\n",
    "print(a.dtype)\n",
    "b = numpy.array([1,2,3,4], dtype=float)\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that once generated, NumPy arrays don't automatically change their type when you insert a value of a different type! For example, if you try to divide the third position of array `a` by 2, it will **not** become `1.5` but instead will be the result of an integer division: `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2] = a[2] / 2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the array with a float data type will do as you might expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[2] = b[2] / 2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Pay attention to data types!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical arrays\n",
    "\n",
    "You can do all sorts of operations on NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a ** 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to single values, you can use all the above operations on NumPy arrays together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4])\n",
    "b = numpy.array([4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a ** b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these are all pointwise operations. For example, for `a * b`, the first element in `a` is multiplied with the first element in `b`, the second element of `a` is multiplied with the second element in `b`, etc. (This is different from *matrix multiplication*, which you might be used to as default if you're a Matlab user.)\n",
    "\n",
    "This means that you can't use arrays of different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4,5])\n",
    "b = numpy.array([4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing arrays\n",
    "\n",
    "Indexing, or choosing values from a collection, is very similar between NumPy arrays and Python lists. The syntax for indexing was using square brackets and the index number you were interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [5,6,7,8,9]\n",
    "my_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = numpy.array([5,6,7,8,9])\n",
    "my_array[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with lists, you can select several indices at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_list[0:2])\n",
    "print(my_array[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean arrays\n",
    "\n",
    "NumPy arrays can also be used in comparisons and with logical operations. For example, you can test which elements in an array are below a certain value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a != 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do pointwise comparisons between two arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4,5])\n",
    "b = numpy.array([5,4,3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a != b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of these comparisons is a Boolean array. This is an array that has True and False elements, and a Boolean `dtype`.\n",
    "\n",
    "A really useful way to employ Boolean arrays is by using them as a *mask*. For example, let's say you did a response time experiment, but don't want to include suspiciously long ones. You can use Boolean arrays to filter these out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array with some response times in milliseconds.\n",
    "rt = numpy.array([500, 234, 455, 7743, 475, 872, 892, 123, 445])\n",
    "# Create a Boolean array for RTs under 2 seconds.\n",
    "low_enough = rt < 2000\n",
    "# Now select only the < 2 second RTs.\n",
    "rt[low_enough]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the 7743 ms time is no longer in the resulting array? Just like indexing, Boolean masks allow you to select data from NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful NumPy functions\n",
    "\n",
    "There are a few basic NumPy functions that can be really useful in practice. A few are described here, but there are *many* more. This overview is nowhere near comprehensive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty(ish) data\n",
    "\n",
    "Sometimes it can be helpful to pre-create an array, for example if you need to complete it line by line. There are several options for this. For all of the following options, you predefine a shape and a data type, and let NumPy create the array.\n",
    "\n",
    "The first options are to create an with only zeros or only ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (5,3)\n",
    "a = numpy.ones(shape, dtype=int)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (5,3)\n",
    "a = numpy.zeros(shape, dtype=int)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy's `empty` does not initialise any values when creating the array. This makes it every so slightly faster than `ones` and `zeros`. However, it does mean you need to make absolutely sure that you indeed fill out the whole array. If you don't, you can end up with strange numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (5,3)\n",
    "a = numpy.empty(shape, dtype=int)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random data\n",
    "\n",
    "In addition to empty arrays, you can also create arrays with random data. There are two super easy options for this. The first allows you to make uniformly distributed random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.random.rand(5,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the generated values are between 0 and 1. You can manipulate them to be between any range you want. For example, to create realistic pixel RGB values, you can multiply them by 255 and then cast them as integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = numpy.random.rand(5,3) * 255\n",
    "rgb = rgb.astype(int)\n",
    "print(rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following approach allows you to make them into any range that you would like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bound = 100\n",
    "high_bound = 300\n",
    "bound_range = high_bound - low_bound\n",
    "random_values = low_bound + (numpy.random.rand(5,3) * bound_range)\n",
    "print(random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another cool trick in NumPy, is that it can produce random data in a normal distribution. This can be a really useful if you would like to ~falsify data for your publication~ produce somewhat realistic data for testing analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.random.randn(5,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values produced by `randn` are sampled from a normal distribution with a mean of 0, and a standard deviation of 1. They are thus easily changed by multiplying them with the your standard deviation of choice, and then adding your mean of choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "sd = 15\n",
    "random_values = m + (numpy.random.randn(5,3) * sd)\n",
    "print(random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final option highlighted here, is that of creating multivariate normal data. This is a normal distribution over several dimensions, and with a predefined covariance matrix. This could be used to create somewhat realistic data for a data analysis concerned with several measurements (*features*) from the same participants (*observations*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of observations and features.\n",
    "n_observations = 5\n",
    "n_features = 3\n",
    "# Set the covariance matrix.\n",
    "cov = [[1.0, 0.5, 0.3],\n",
    "       [0.5, 1.0, 0.2],\n",
    "       [0.3, 0.2, 1.0]]\n",
    "# Generate a random mean for each feature.\n",
    "means = numpy.random.rand(n_features)\n",
    "# Create the random data.\n",
    "random_values = numpy.random.multivariate_normal(means, cov, size=n_observations)\n",
    "\n",
    "print(random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One potentially important thing to keep in mind, is that this \"random\" data is not actually completely random. In fact, it's the product of a highly predictable algorithm on your computer. This is called *pseudo-random*, and is often enough. But it is good to keep in mind that it is not truly random. (What is truly random? The decay of a unstable nucleus in radioactive material, atmospheric noise, that kind of thing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrays in spaaaaaaace\n",
    "\n",
    "In addition to empty(ish) arrays, you can create arrays in linear or non-linear spaces. For example, the output of Python's `range` function could be turned into a list of successive values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list from 0 to 10 (not inclusive)\n",
    "# with stepsize 1:\n",
    "list(range(0, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list from 5 to 15 (not inclusive)\n",
    "# with stepsize 1:\n",
    "list(range(5, 15, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list from 5 to 15 (not inclusive)\n",
    "# with stepsize 3:\n",
    "list(range(5, 15, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy function `arange` can do the same things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array from 0 to 10 (not inclusive)\n",
    "# with stepsize 1:\n",
    "numpy.arange(0, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array from 5 to 15 (not inclusive)\n",
    "# with stepsize 1:\n",
    "numpy.arange(5, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array from 5 to 15 (not inclusive)\n",
    "# with stepsize 3:\n",
    "numpy.arange(5, 15, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Python's `range`, NumPy's `arange` can also do floats. Exciting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array from 0 to 5 (not inclusive)\n",
    "# with stepsize 0.5:\n",
    "numpy.arange(0, 5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to bother with computing step sizes, you can rely on NumPy's `linspace`. You can give it a starting value, an ending value, and the number of values you'd like in your array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array from 0 to 10 (inclusive)\n",
    "# with 5 elements.\n",
    "numpy.linspace(0, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pull the same trick but in logarithmic space by using NumPy's `logspace`. This function will create a number of values from $base^start$ to $base^end$. For example, let's take base 2, and create values from $2^0$ to $2^8$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array from 2**0 to 2**8 (inclusive)\n",
    "# with 9 elements.\n",
    "numpy.logspace(0, 8, 9, base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding values in arrays\n",
    "\n",
    "In a list, you could simply use the `index` function to find the index for specific value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [5,6,7,8,9]\n",
    "a.index(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a NumPy array, you can use the `where` function. There is a slightly different logic to this, as it allows you to scan the whole array in one go. You supply the `where` function with a conditional statement, which in this case would be `a == 7`. The function then gives you a tuple with the indices for your array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array([5,6,7,8,9])\n",
    "numpy.where(a == 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from files\n",
    "\n",
    "So far, you've only seen data that was typed in, or pseudo-randomly generated. In practice, data often comes from text files. Such text files are often formatted as comma-separated values (csv) or tab-separated values (tsv). If you open such a file in Excel, they're likely automatically parsed. However, if you open it in a text editor, you'll see something like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ppnr,feature_1,feature_2\n",
    "    1,-1.0280283509,-0.6330093174\n",
    "    2,-0.68246167,-0.8524370369\n",
    "    3,-1.573580474,-1.8449423168\n",
    "    4,0.5898308063,-0.8070221829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ppnr\tfeature_1\tfeature_2\n",
    "    1\t-1.0280283509\t-0.6330093174\n",
    "    2\t-0.68246167\t-0.8524370369\n",
    "    3\t-1.573580474\t-1.8449423168\n",
    "    4\t0.5898308063\t-0.8070221829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files can also be loaded into Python. One option is to use the basic Python functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"example.csv\"\n",
    "\n",
    "# Open the text file in READ (\"r\") mode.\n",
    "with open(file_name, \"r\") as open_file:\n",
    "    file_content = open_file.readlines()\n",
    "\n",
    "# Print all lines.\n",
    "for line in file_content:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so that's a lot, and not necessarily in the most useful format... You'd first have to parse the header (the first line), so that you know what variables to make. You'd then have to parse each line, and then store the data in the correct variable for it. UGH, effort...\n",
    "\n",
    "Just for the record, such a parser would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"example.csv\"\n",
    "\n",
    "# Open the text file in READ (\"r\") mode.\n",
    "with open(file_name, \"r\") as open_file:\n",
    "    file_content = open_file.readlines()\n",
    "\n",
    "# Start with an empty dictionary.\n",
    "my_data = {}\n",
    "\n",
    "# Count the number of participants. This is the\n",
    "# number of lines minus the header.\n",
    "n_observations = len(file_content) - 1\n",
    "\n",
    "# Go through all lines.\n",
    "for i, line in enumerate(file_content):\n",
    "    # Remove the newline from the end of the line.\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    # Split the line to get individual values.\n",
    "    values = line.split(\",\")\n",
    "    # If this is the first line, it will be the header.\n",
    "    if i == 0:\n",
    "        # Copy the values into a variable called \"header\".\n",
    "        header = values[:]\n",
    "        # Loop through all variables.\n",
    "        for var_name in values:\n",
    "            my_data[var_name] = numpy.zeros(n_observations, \n",
    "                dtype=float)\n",
    "    # For any other value, add the value in the right place.\n",
    "    else:\n",
    "        for j, val in enumerate(values):\n",
    "            # Choose the right variable name for this\n",
    "            # value.\n",
    "            var_name = header[j]\n",
    "            # Store the value in the right location.\n",
    "            # This is the current line, i, minus one\n",
    "            # to correct for the header being the\n",
    "            # first line.\n",
    "            my_data[var_name][i-1] = val\n",
    "\n",
    "# Print the data to the page to show that it\n",
    "# was loaded correctly.\n",
    "for var_name in my_data.keys():\n",
    "    print(var_name, my_data[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so clearly this is a bit of a faff. Fortunately, NumPy offers a quicker way to do this! You can use its `loadtxt` function to read your data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"example.csv\"\n",
    "\n",
    "# This reads the data, but skips the header.\n",
    "my_data = numpy.loadtxt(file_name, delimiter=\",\", \n",
    "    skiprows=1)\n",
    "\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this option worked well if you know what the header is, but otherwise you might be a bit confused. You could simply load the first line in the more traditional way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"example.csv\"\n",
    "\n",
    "# Open the text file in READ (\"r\") mode.\n",
    "with open(file_name, \"r\") as open_file:\n",
    "    # Read only the first row, to get the header.\n",
    "    first_line = open_file.readline()\n",
    "# Parse the header by removing the newline on\n",
    "# the end, and then splitting it by commas.\n",
    "header = first_line.replace(\"\\n\", \"\")\n",
    "header = header.split(\",\")\n",
    "\n",
    "# This reads the data, but skips the header.\n",
    "my_data = numpy.loadtxt(file_name, delimiter=\",\", \n",
    "    skiprows=1)\n",
    "\n",
    "print(header)\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a more elegant option could be to load the data into a `dict`, with a key for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"example.csv\"\n",
    "\n",
    "# Specify which columns should not be cast as float.\n",
    "no_casting = [\"ppnr\"]\n",
    "\n",
    "# This reads the data, but all as string values.\n",
    "raw_data = numpy.loadtxt(file_name, delimiter=\",\", \n",
    "    dtype=str)\n",
    "\n",
    "# Create an empty dict to hold the data.\n",
    "my_data = {}\n",
    "\n",
    "# Go through all columns in the data.\n",
    "for i in range(raw_data.shape[1]):\n",
    "    # Get the variable name. This will be the\n",
    "    # first entry in this column.\n",
    "    var_name = raw_data[0,i]\n",
    "    # Now get all the values. This will be all\n",
    "    # other rows.\n",
    "    val = raw_data[1:,i]\n",
    "    # Try to convert the values to floats, but\n",
    "    # only for those values that were supposed\n",
    "    # to be converted, and simply ignore when\n",
    "    # the values could not be converted.\n",
    "    if var_name not in no_casting:\n",
    "        try:\n",
    "            val = val.astype(float)\n",
    "        # And simply ignore when that fails.\n",
    "        except:\n",
    "            pass\n",
    "    # Now store the data in the dict.\n",
    "    my_data[var_name] = val\n",
    "\n",
    "# Print the data to the page to show that it\n",
    "# was loaded correctly.\n",
    "for var_name in my_data.keys():\n",
    "    print(var_name, my_data[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on paths\n",
    "\n",
    "A path is like an address on your computer. It tells your code exactly where to look for a specific file. For example, this could be `C:\\User\\Edwin\\Documents\\example.csv` of Windows, or `/home/Edwin/Documents/example.csv` on Linux. These are called **absolute paths**, as they describe exactly where a file is.\n",
    "\n",
    "There are also **relative paths** that describe where a file is with respect to the current location. For example, from the folder `Edwin` in the previous example, a relative path could be `./Documents/example.csv`.\n",
    "\n",
    "In Python, you can use the `os` module to deal with things to do with the Operating System (OS). The `os.path` module specifically can make your life a lot easier when dealing with paths! For example, you might have already noticed the difference between `\\` and `/` in Windows and Linux. This difference can be circumvented by using `os.join`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "my_folder = \"Documents\"\n",
    "my_file = \"example.csv\"\n",
    "my_path = os.path.join(my_folder,my_file)\n",
    "\n",
    "print(my_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running a Python file in a non-Jupyter environment, Python will automatically create the `__file__` variable. This holds the path to the file that is being run. For example, if you run `script.py` in the `/home/Edwin/Documents` folder, `__file__` would be `/home/Edwin/Documents/script.py`. You can use this to automatically detect the folder that your file is in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just for the Jupyter environment:\n",
    "if (\"__file__\" not in locals()) and (\"__file__\" not in globals()):\n",
    "    __file__ = \"/home/User/Documents/script.py\"\n",
    "\n",
    "# Get the current file name.\n",
    "this_file = __file__\n",
    "print(\"Running file '{}''\".format(this_file))\n",
    "\n",
    "# Get the name of the folder that this\n",
    "# file is in.\n",
    "this_dir = os.path.dirname(this_file)\n",
    "print(\"The current folder is {}\".format(this_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `os.path` module to split file names and extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example file name.\n",
    "example_file = \"example.csv\"\n",
    "\n",
    "# Split the name and extension.\n",
    "name, ext = os.path.splitext(example_file)\n",
    "\n",
    "# Use the extension to do something.\n",
    "if ext == \".csv\":\n",
    "    print(\"This file contains comma-separated values.\")\n",
    "elif ext == \".tsv\":\n",
    "    print(\"This file contains tab-separated values.\")\n",
    "else:\n",
    "    print(\"This file has a '{}' extension.\".format(ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the above all together, you could detect the folder where you keep your data from your analysis script without having to ever write an exact path. This makes your code much more reproducibly, as you don't have to rewrite it if you move the code.\n",
    "\n",
    "Assume you have the following file structure:\n",
    "\n",
    "- /home/User/Documents/\n",
    "    - script.py\n",
    "    - /data\n",
    "        - participant_01.csv\n",
    "        - participant_02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just for the Jupyter environment:\n",
    "if (\"__file__\" not in locals()) and (\"__file__\" not in globals()):\n",
    "    __file__ = \"/home/User/Documents/script.py\"\n",
    "\n",
    "# Get the path to the current script.\n",
    "current_dir = os.path.dirname(__file__)\n",
    "# Construct the path to the data folder.\n",
    "data_dir = os.path.join(current_dir, \"data\")\n",
    "\n",
    "# Check if the data directory exists.\n",
    "if os.path.isdir(data_dir):\n",
    "    # Get a list of all files in the data directory.\n",
    "    data_files = os.listdir(data_dir)\n",
    "# If the data directory does not exist, say so.\n",
    "else:\n",
    "    print(\"Directory does not exist: {}\".format(data_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
